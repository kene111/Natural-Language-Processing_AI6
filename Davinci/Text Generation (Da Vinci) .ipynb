{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of text: 8875 characters\n"
     ]
    }
   ],
   "source": [
    "text = open('vinci.txt', 'rb').read().decode(encoding='utf-8')\n",
    "length = len(text)\n",
    "print(f'length of text: {length} characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge of the past and of the places of the earth is the ornament and food of the mind of man.\n",
      "The noblest pleasure is the joy of understanding.\n",
      "As a well-spent day brings happy sleep, so a life well spent brings happy death.\n",
      "Learning never exhausts the mind.\n",
      "To such an extent does nature delight\n"
     ]
    }
   ],
   "source": [
    "# Printing the first 300 characters in the text.\n",
    "print(text[: 300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 60 unique characters\n"
     ]
    }
   ],
   "source": [
    "# Displaying the unique characters in life.\n",
    "unique = sorted(set(text))\n",
    "print(f'There are {len(unique)} unique characters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizing the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we would map all the unique characters to their indices\n",
    "char_idx = {u:i for i, u in enumerate(unique)}\n",
    "#idx_char = {i:u for i, u in enumerate(unique)}\n",
    "idx_char = np.array(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\\n' : 0\n",
      "' ' : 1\n",
      "'!' : 2\n",
      "\"'\" : 3\n",
      "',' : 4\n",
      "'-' : 5\n",
      "'.' : 6\n",
      "'0' : 7\n",
      "'1' : 8\n",
      "'3' : 9\n",
      "':' : 10\n",
      "';' : 11\n",
      "'?' : 12\n",
      "'A' : 13\n",
      "'B' : 14\n",
      "'C' : 15\n",
      "'D' : 16\n",
      "'E' : 17\n",
      "'F' : 18\n",
      "'G' : 19\n"
     ]
    }
   ],
   "source": [
    "# printing out the first 20 elements in the char_idx dictionary\n",
    "for charc,_ in zip(char_idx, range(20)):\n",
    "    print(f'{repr(charc)} : {char_idx[charc]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the same goes for the idx_char dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "integer_text = np.array([char_idx[c] for c in text])  \n",
    "# It is better to put it in an array than to leave it in form of a list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Knowledge of the' --- in integer form is --- -> [23 47 48 56 45 38 37 40 38  1 48 39  1 53 41 38]\n"
     ]
    }
   ],
   "source": [
    "# so ...\n",
    "print(f'{repr(text[:16])} --- in integer form is --- -> {integer_text[:16]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 103 # Number of length sentence we want for the input of a single character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating training examples and targets\n",
    "character_dataset = tf.data.Dataset.from_tensor_slices(integer_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K\n",
      "n\n",
      "o\n",
      "w\n",
      "l\n"
     ]
    }
   ],
   "source": [
    "# How it looks\n",
    "for i in character_dataset.take(5):\n",
    "    print(idx_char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Knowledge of the past and of the places of the earth is the ornament and food of the mind of man.\\nThe n'\n",
      "'oblest pleasure is the joy of understanding.\\nAs a well-spent day brings happy sleep, so a life well spe'\n",
      "'nt brings happy death.\\nLearning never exhausts the mind.\\nTo such an extent does nature delight and abou'\n"
     ]
    }
   ],
   "source": [
    "sequences = character_dataset.batch(sequence_length, drop_remainder= True)\n",
    "''' what drop_remainder does is, if the actual length of a sentence is 120 and we take a character lenght(which is the sequence_length) of 103,\n",
    "the remaining length of characters which is 17 should be dropped/discarded.\n",
    "''' \n",
    "\"\"\" The batch works like this : [1 2 3 4 5 6 7 8 9 10], for a batch size of 3\n",
    "we have, ['1 2 3' '4 5 6' '7 8 9'], 10 is dropped. I ignored the whitespaces for this explanation\"\"\"\n",
    "# Let's see how this looks like.\n",
    "for i in sequences.take(3):\n",
    "    print(repr(''.join(idx_char[i.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(portion):\n",
    "    input_text = portion[:-1]\n",
    "    target_text = portion[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 3\n",
    "BUFFER_SIZE = 30 # It is good practise to set your buffer_size to the length of your dataset or higher, it makes the shuffling more uniform, but this applies to large datasets.\n",
    "# since the dataset isn't very large I would use a smaller buffer\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = len(unique)\n",
    "embedding_dim = 256\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocabulary_size, embedding_dim, rnn_units, batch_size):\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Embedding(vocabulary_size, embedding_dim, batch_input_shape = [batch_size, None]))\n",
    "    model.add(tf.keras.layers.LSTM(rnn_units, return_sequences = True, stateful = True, recurrent_initializer = 'orthogonal'))\n",
    "    model.add(tf.keras.layers.Dense(vocabulary_size))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sequential() : Basically used to create a linear stack for the layers to be added.\n",
    "#Embedding(): This turns integers into a dense vector space. This link explains it better  \"https://stats.stackexchange.com/questions/270546/how-does-keras-embedding-layer-work\"\n",
    "#LSTM(): A variety of the RRN model. This liink explains it well \"https://www.analyticsvidhya.com/blog/2017/12/fundamentals-of-deep-learning-introduction-to-lstm/\"\n",
    "#Dense(): Is the normal fully connected layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "    vocabulary_size = len(unique),\n",
    "    embedding_dim = embedding_dim,\n",
    "    rnn_units = rnn_units,\n",
    "    batch_size = BATCH_SIZE\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (3, None, 256)            15360     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (3, None, 1024)           5246976   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (3, None, 60)             61500     \n",
      "=================================================================\n",
      "Total params: 5,323,836\n",
      "Trainable params: 5,323,836\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basically used in finding the difference between to the predicted target value and actual target value\n",
    "\n",
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss) #model.compile(optimizer = 'RMSProp', loss = loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves the model after every epoch.\n",
    "\n",
    "#---------------------------------------------\n",
    "#Directory where the model is saved.\n",
    "checkpoint_directory = './Training_checkpoints'\n",
    "\n",
    "# Accesing the directory.\n",
    "checkpoint_prefix = os.path.join(checkpoint_directory, 'ckpt_{epoch}')\n",
    "\n",
    "#\n",
    "checkpoint_call_back = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_prefix, save_weights_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1217 16:57:47.046068  8568 deprecation.py:323] From C:\\Users\\Kenechi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 283s 10s/step - loss: 3.2928\n",
      "Epoch 2/25\n",
      "28/28 [==============================] - 270s 10s/step - loss: 2.9007\n",
      "Epoch 3/25\n",
      "28/28 [==============================] - 282s 10s/step - loss: 2.6427\n",
      "Epoch 4/25\n",
      "28/28 [==============================] - 343s 12s/step - loss: 2.4007\n",
      "Epoch 5/25\n",
      "28/28 [==============================] - 7978s 285s/step - loss: 2.2673\n",
      "Epoch 6/25\n",
      "28/28 [==============================] - 525s 19s/step - loss: 2.1753\n",
      "Epoch 7/25\n",
      "28/28 [==============================] - 533s 19s/step - loss: 2.0867\n",
      "Epoch 8/25\n",
      "28/28 [==============================] - 525s 19s/step - loss: 1.9986\n",
      "Epoch 9/25\n",
      "28/28 [==============================] - 521s 19s/step - loss: 1.9094\n",
      "Epoch 10/25\n",
      "28/28 [==============================] - 527s 19s/step - loss: 1.8079\n",
      "Epoch 11/25\n",
      "28/28 [==============================] - 524s 19s/step - loss: 1.6848\n",
      "Epoch 12/25\n",
      "28/28 [==============================] - 527s 19s/step - loss: 1.5377\n",
      "Epoch 13/25\n",
      "28/28 [==============================] - 511s 18s/step - loss: 1.3750\n",
      "Epoch 14/25\n",
      "28/28 [==============================] - 500s 18s/step - loss: 1.2064\n",
      "Epoch 15/25\n",
      "28/28 [==============================] - 496s 18s/step - loss: 1.0403\n",
      "Epoch 16/25\n",
      "28/28 [==============================] - 503s 18s/step - loss: 0.8561\n",
      "Epoch 17/25\n",
      "28/28 [==============================] - 501s 18s/step - loss: 0.6764\n",
      "Epoch 18/25\n",
      "28/28 [==============================] - 497s 18s/step - loss: 0.5272\n",
      "Epoch 19/25\n",
      "28/28 [==============================] - 508s 18s/step - loss: 0.3943\n",
      "Epoch 20/25\n",
      "28/28 [==============================] - 519s 19s/step - loss: 0.2690\n",
      "Epoch 21/25\n",
      "28/28 [==============================] - 510s 18s/step - loss: 0.1716\n",
      "Epoch 22/25\n",
      "28/28 [==============================] - 507s 18s/step - loss: 0.1064\n",
      "Epoch 23/25\n",
      "28/28 [==============================] - 509s 18s/step - loss: 0.0688\n",
      "Epoch 24/25\n",
      "28/28 [==============================] - 508s 18s/step - loss: 0.0450\n",
      "Epoch 25/25\n",
      "28/28 [==============================] - 444s 16s/step - loss: 0.0282\n"
     ]
    }
   ],
   "source": [
    "learning = model.fit(dataset, epochs = Epochs, callbacks = [checkpoint_call_back])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this finds the latest saved check point\n",
    "trained_weights= tf.train.latest_checkpoint(checkpoint_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building another model, and feeding the trained weights from 'learning' into it ... \n",
    "model = build_model( vocabulary_size = len(unique),embedding_dim = embedding_dim, rnn_units = rnn_units,batch_size = 1)\n",
    "model.load_weights(trained_weights)\n",
    "model.build(tf.TensorShape([1,None]))  # TensorShape() shapes a tensor, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 256)            15360     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (1, None, 1024)           5246976   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 60)             61500     \n",
      "=================================================================\n",
      "Total params: 5,323,836\n",
      "Trainable params: 5,323,836\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generating_the_text(model, starting_string):\n",
    "    \n",
    "    # number of characters to generate\n",
    "    number_generated= 1500\n",
    "    \n",
    "    # converting the starting string to vector\n",
    "    s_s_vector = [char_idx[s] for s in starting_string]\n",
    "    \n",
    "    # inserting a dimesion of one into a tensors shape, here it adds a dimension at index 0\n",
    "    s_s_vector = tf.expand_dims(s_s_vector,0)\n",
    "    \n",
    "    # To store our results\n",
    "    text_generated = []\n",
    "    \n",
    "    temperature = 0.9\n",
    "    # the closer the temperature is to zero the more predictable text we have.\n",
    "    # the closer the temperature is to one the more unpredictable text we have.\n",
    "    \n",
    "    model.reset_states() #\n",
    "    for i in range(number_generated):\n",
    "        predict = model(s_s_vector)\n",
    "        \n",
    "        predict = tf.squeeze(predict, 0)# Used in removing a dimension or specified dimension, here it removes the dimension at index 0\n",
    "        \n",
    "        predict = predict / temperature\n",
    "        \n",
    "        predicted_idx = tf.random.categorical(predict, num_samples = 1)[-1,0].numpy() # this applies the princniples of categorical distribution this link explains it 'https://stackoverflow.com/questions/55063120/can-anyone-give-a-tiny-example-to-explain-the-params-of-tf-random-categorical'\n",
    "        \n",
    "        \n",
    "        s_s_vector = tf.expand_dims([predicted_idx], 0)\n",
    "        \n",
    "        text_generated.append(idx_char[predicted_idx])\n",
    "        \n",
    "    return (starting_string + ''.join(text_generated))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prainses in the representation of visible things and can eDflucts for dishowly which exws core dille purcains and domin of muscle is to pull and not to push, except in the caseare work and Porivion, Dore and Powit, an, ther whose heart is firm, things is the chief not is not enough.\n",
      "Ye who boy sf sence not and propinquity, Motion and Rest.\n",
      "Man is formett of being hap is may be istenale object so arr in erecting the brain.\n",
      "I love those who can smile in trouble, who can gal and end to be pest descting haus not from her what is not is neoush is the manot of what body is dependant on Heaven and Heaven on the Spirit.\n",
      "Time stays long enough for anyone who will user a the dinks.\n",
      "The I manks of which are: it love it only little or not at all.\n",
      "Weight, force and casual immore deminging the haman body as compared with the bodies of the painter must resemble a mirror, which always takes the colour of the object it reflects and is completely occupied by the images of as many objects as are in front of it.\n",
      "The mind of the wind.\n",
      "Just as courage is the danger of life, so is fear its sham the organic instruments of that bodies display their foum not.\n",
      "Why does the eye see a thing more clatlout will net eser and the Spirit.\n",
      "Time stals long enough for anyone who will uses is knowledge.\n",
      "He who is fixed to a star does not change his mind.\n",
      "The Medici treat work hody is like, in inoull a maror which always takes the colour of the object it reflects and is completely occupied by the images of as man\n"
     ]
    }
   ],
   "source": [
    "print(generating_the_text(model, starting_string ='The'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ..............changing the optimizer used ............................"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocabulary_size, embedding_dim, rnn_units, batch_size):\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Embedding(vocabulary_size, embedding_dim, batch_input_shape = [batch_size, None]))\n",
    "    model.add(tf.keras.layers.LSTM(rnn_units, return_sequences = True, stateful = True, recurrent_initializer = 'orthogonal'))\n",
    "    model.add(tf.keras.layers.Dense(vocabulary_size))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = build_model(\n",
    "    vocabulary_size = len(unique),\n",
    "    embedding_dim = embedding_dim,\n",
    "    rnn_units = rnn_units,\n",
    "    batch_size = BATCH_SIZE\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (3, None, 256)            15360     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (3, None, 1024)           5246976   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (3, None, 60)             61500     \n",
      "=================================================================\n",
      "Total params: 5,323,836\n",
      "Trainable params: 5,323,836\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.compile(optimizer = 'RMSProp', loss = loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves the model after every epoch.\n",
    "\n",
    "#---------------------------------------------\n",
    "#Directory where the model is saved.\n",
    "checkpoint_directory = './Training_checkpoints_2'\n",
    "\n",
    "# Accesing the directory.\n",
    "checkpoint_prefix = os.path.join(checkpoint_directory, 'ckpt_{epoch}')\n",
    "\n",
    "#\n",
    "checkpoint_call_back = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_prefix, save_weights_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "28/28 [==============================] - 231s 8s/step - loss: 3.3647\n",
      "Epoch 2/25\n",
      "28/28 [==============================] - 231s 8s/step - loss: 2.7544\n",
      "Epoch 3/25\n",
      "28/28 [==============================] - 232s 8s/step - loss: 2.4383\n",
      "Epoch 4/25\n",
      "28/28 [==============================] - 225s 8s/step - loss: 2.2815\n",
      "Epoch 5/25\n",
      "28/28 [==============================] - 225s 8s/step - loss: 2.1627\n",
      "Epoch 6/25\n",
      "28/28 [==============================] - 230s 8s/step - loss: 2.0599\n",
      "Epoch 7/25\n",
      "28/28 [==============================] - 229s 8s/step - loss: 1.9433\n",
      "Epoch 8/25\n",
      "28/28 [==============================] - 231s 8s/step - loss: 1.8127\n",
      "Epoch 9/25\n",
      "28/28 [==============================] - 232s 8s/step - loss: 1.6649\n",
      "Epoch 10/25\n",
      "28/28 [==============================] - 227s 8s/step - loss: 1.4895\n",
      "Epoch 11/25\n",
      "28/28 [==============================] - 230s 8s/step - loss: 1.3025\n",
      "Epoch 12/25\n",
      "28/28 [==============================] - 230s 8s/step - loss: 1.1079\n",
      "Epoch 13/25\n",
      "28/28 [==============================] - 229s 8s/step - loss: 0.9118\n",
      "Epoch 14/25\n",
      "28/28 [==============================] - 230s 8s/step - loss: 0.7269\n",
      "Epoch 15/25\n",
      "28/28 [==============================] - 228s 8s/step - loss: 0.5467\n",
      "Epoch 16/25\n",
      "28/28 [==============================] - 228s 8s/step - loss: 0.4039\n",
      "Epoch 17/25\n",
      "28/28 [==============================] - 235s 8s/step - loss: 0.2882\n",
      "Epoch 18/25\n",
      "28/28 [==============================] - 235s 8s/step - loss: 0.2047\n",
      "Epoch 19/25\n",
      "28/28 [==============================] - 234s 8s/step - loss: 0.1439\n",
      "Epoch 20/25\n",
      "28/28 [==============================] - 237s 8s/step - loss: 0.1064\n",
      "Epoch 21/25\n",
      "28/28 [==============================] - 231s 8s/step - loss: 0.0819\n",
      "Epoch 22/25\n",
      "28/28 [==============================] - 229s 8s/step - loss: 0.0611\n",
      "Epoch 23/25\n",
      "28/28 [==============================] - 224s 8s/step - loss: 0.0579\n",
      "Epoch 24/25\n",
      "28/28 [==============================] - 225s 8s/step - loss: 0.0412\n",
      "Epoch 25/25\n",
      "28/28 [==============================] - 229s 8s/step - loss: 0.0403\n"
     ]
    }
   ],
   "source": [
    "learning_2 = model_1.fit(dataset, epochs = Epochs, callbacks = [checkpoint_call_back])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_weights_2= tf.train.latest_checkpoint(checkpoint_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building another model, and feeding the trained weights from 'learning' into it ... \n",
    "model_2 = build_model( vocabulary_size = len(unique),embedding_dim = embedding_dim, rnn_units = rnn_units,batch_size = 1)\n",
    "model_2.load_weights(trained_weights_2)\n",
    "model_2.build(tf.TensorShape([1,None]))  # TensorShape() shapes a tensor, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (1, None, 256)            15360     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (1, None, 1024)           5246976   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (1, None, 60)             61500     \n",
      "=================================================================\n",
      "Total params: 5,323,836\n",
      "Trainable params: 5,323,836\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mant astion breater or less than that ave is not in her in hor do is like, in the hope of pulling o than a of sence in the cast and laves by as mame is out pesile is the joy of understanding is not becedsand of the tinds, which we will prove by the ie co dasterpiece of engineerinc and a worke is loys is auterilut, and fout all mer stals and the forition of the mind.\n",
      "Taus the corrace of the earth is the misclear purts in e uster ince infer in haver and inventrention not appayse in the air, it is first necessary to acquire knowledge of the winds, which we will prove by the death of the painter must resemble a mirror, which always takes the colour of the object it reflects and is completely occupied by the images of as many objects; the third, and thet at ats.\n",
      "Teer, a to attritage are the tont antion whece ho dound the least work are most active.\n",
      "The truth of things is the chief nutriment of superior intellect, a mistle is the thiencoulite without theory ace the thuth of things is the chief nutriment of superior intellect, desire and covetousness. The two firs and which muscle, by swelling, cauchine is the contrection of that sinew; and which muscle, by swelling, caumale and invention more beautiful, more simple or more direct than does nature because in her invention .o dacter what hear and condacs with the urgency of doing. Knowing is not enough; we the their dor more all im frecth mencaps and of the thithe, the truth of things is the chief nutriment of superior intellecth an\n"
     ]
    }
   ],
   "source": [
    "print(generating_the_text(model_2, starting_string ='The'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data used was too small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.......................... using a GRU ............................."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocabulary_size, embedding_dim, rnn_units, batch_size):\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Embedding(vocabulary_size, embedding_dim, batch_input_shape = [batch_size, None]))\n",
    "    model.add(tf.keras.layers.GRU(rnn_units, return_sequences = True, stateful = True, recurrent_initializer = 'glorot_uniform'))\n",
    "    model.add(tf.keras.layers.Dense(vocabulary_size))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3= build_model(\n",
    "    vocabulary_size = len(unique),\n",
    "    embedding_dim = embedding_dim,\n",
    "    rnn_units = rnn_units,\n",
    "    batch_size = BATCH_SIZE\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (3, None, 256)            15360     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (3, None, 1024)           3935232   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (3, None, 60)             61500     \n",
      "=================================================================\n",
      "Total params: 4,012,092\n",
      "Trainable params: 4,012,092\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.compile(optimizer = 'adam', loss = loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves the model after every epoch.\n",
    "\n",
    "#---------------------------------------------\n",
    "#Directory where the model is saved.\n",
    "checkpoint_directory = './Training_checkpoints_3'\n",
    "\n",
    "# Accesing the directory.\n",
    "checkpoint_prefix = os.path.join(checkpoint_directory, 'ckpt_{epoch}')\n",
    "\n",
    "#\n",
    "checkpoint_call_back = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_prefix, save_weights_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "28/28 [==============================] - 224s 8s/step - loss: 3.5368\n",
      "Epoch 2/25\n",
      "28/28 [==============================] - 216s 8s/step - loss: 2.7431\n",
      "Epoch 3/25\n",
      "28/28 [==============================] - 229s 8s/step - loss: 2.4141\n",
      "Epoch 4/25\n",
      "28/28 [==============================] - 224s 8s/step - loss: 2.2632\n",
      "Epoch 5/25\n",
      "28/28 [==============================] - 214s 8s/step - loss: 2.1707\n",
      "Epoch 6/25\n",
      "28/28 [==============================] - 218s 8s/step - loss: 2.0937\n",
      "Epoch 7/25\n",
      "28/28 [==============================] - 197s 7s/step - loss: 2.0104\n",
      "Epoch 8/25\n",
      "28/28 [==============================] - 216s 8s/step - loss: 1.9162\n",
      "Epoch 9/25\n",
      "28/28 [==============================] - 216s 8s/step - loss: 1.8093\n",
      "Epoch 10/25\n",
      "28/28 [==============================] - 250s 9s/step - loss: 1.6862\n",
      "Epoch 11/25\n",
      "28/28 [==============================] - 220s 8s/step - loss: 1.5413\n",
      "Epoch 12/25\n",
      "28/28 [==============================] - 209s 7s/step - loss: 1.3787\n",
      "Epoch 13/25\n",
      "28/28 [==============================] - 213s 8s/step - loss: 1.2178\n",
      "Epoch 14/25\n",
      "28/28 [==============================] - 212s 8s/step - loss: 1.0530\n",
      "Epoch 15/25\n",
      "28/28 [==============================] - 205s 7s/step - loss: 0.8611\n",
      "Epoch 16/25\n",
      "28/28 [==============================] - 209s 7s/step - loss: 0.7094\n",
      "Epoch 17/25\n",
      "28/28 [==============================] - 223s 8s/step - loss: 0.5459\n",
      "Epoch 18/25\n",
      "28/28 [==============================] - 214s 8s/step - loss: 0.3759\n",
      "Epoch 19/25\n",
      "28/28 [==============================] - 210s 7s/step - loss: 0.2753\n",
      "Epoch 20/25\n",
      "28/28 [==============================] - 226s 8s/step - loss: 0.1965\n",
      "Epoch 21/25\n",
      "28/28 [==============================] - 206s 7s/step - loss: 0.1153\n",
      "Epoch 22/25\n",
      "28/28 [==============================] - 209s 7s/step - loss: 0.0723\n",
      "Epoch 23/25\n",
      "28/28 [==============================] - 298s 11s/step - loss: 0.0481\n",
      "Epoch 24/25\n",
      "28/28 [==============================] - 212s 8s/step - loss: 0.0286\n",
      "Epoch 25/25\n",
      "28/28 [==============================] - 219s 8s/step - loss: 0.0211\n"
     ]
    }
   ],
   "source": [
    "learning_3 = model_3.fit(dataset, epochs = Epochs, callbacks = [checkpoint_call_back])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_weights_3= tf.train.latest_checkpoint(checkpoint_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building another model, and feeding the trained weights from 'learning' into it ... \n",
    "model_4 = build_model( vocabulary_size = len(unique),embedding_dim = embedding_dim, rnn_units = rnn_units,batch_size = 1)\n",
    "model_4.load_weights(trained_weights_3)\n",
    "model_4.build(tf.TensorShape([1,None]))  # TensorShape() shapes a tensor, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (1, None, 256)            15360     \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (1, None, 1024)           3935232   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (1, None, 60)             61500     \n",
      "=================================================================\n",
      "Total params: 4,012,092\n",
      "Trainable params: 4,012,092\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mind of the painter must resemble a mirror, which always takes the colour of the object it reflects and is completely occupied by the images of as many objects as are in front of it.\n",
      "The mind of the painter must resemble a mirror, which always takes the colour of the object it reflects and is completely occupied by the images of as many objects as are in front of it.\n",
      "The mind of the painter must reselbal to a lifb, how many and which sinews, expanded into the thinnest cartilage, surround and the first of that which copies every thing placed in front of it without bearu wall the joy of undanst one well spent is long.\n",
      "He who wishes to be rich in a day will ne a soe woll whe boly eyrs the painter in the representation of visible things, and far below the painter in the representation of visible things, and far below the painter in the representation of visible things, and far below the painter in the representation of visible things, and far below the painter in the representation of visible things, and far below the painter in the representation of visible things, and far below the painter in the representation of visible things, and far deingh and thing more clearly in dreams than the imagination when awern body andiHe then shall a suple ot the griate f on tree knowledge of the winds, which we will prove by the images of as many objects as are in front of it.\n",
      "The mind of the painter must resemble a mirror, which always takes the colour of the object it reflects and is complet\n"
     ]
    }
   ],
   "source": [
    "print(generating_the_text(model_4, starting_string ='The'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks like the GRU model over-fitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference : https://www.tensorflow.org/tutorials/text/text_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
